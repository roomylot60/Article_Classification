# 네이버 뉴스 크롤링 및 감성 분석 웹 애플리케이션

## 프로젝트 개요
이 프로젝트는 **네이버 뉴스**의 특정 섹션(정치, 경제, 사회 등)에서 기사를 크롤링한 뒤, **자연어 처리**를 통해 기사 **요약**과 **감성 분석**을 수행하는 웹 애플리케이션입니다. 백엔드에 FastAPI를 사용하고 프론트엔드에 Streamlit을 적용하여, 사용자에게 분석 결과를 대화형 대시보드 형태로 제공합니다. 크롤링된 기사와 분석 결과는 MySQL 데이터베이스에 저장되며, 이를 통해 **데이터 수집**, **전처리**, **분석**, **시각화** 및 **배포**에 이르는 전 과정을 포괄하는 엔드투엔드(E2E) 데이터 사이언스 파이프라인을 구현합니다.

## 사용 기술 스택
- **언어 및 프레임워크**: Python (FastAPI, Streamlit)
- **데이터베이스**: MySQL (mysql-connector-python)
- **웹 크롤링**: `requests`, `BeautifulSoup`
- **자연어 처리 (NLP)**: Hugging Face `transformers` 라이브러리  
  - 요약: `digit82/kobart-summarization` 모델  
  - 감성 분석: `snunlp/KR-FinBERT` 모델  
- **비동기 처리**: `asyncio`, `aiohttp`
- **API 개발 및 배포**: FastAPI, Uvicorn 
- **UI 개발**: Streamlit (데이터 시각화 및 인터랙티브 대시보드)

## 코드 및 기술적 구현

### 1. 뉴스 크롤링 (`news_scraper.py`)
- **네이버 뉴스 섹션 페이지 크롤링**: `requests`와 `BeautifulSoup`을 사용하여 각 섹션별 뉴스 목록 및 기사 페이지를 가져옵니다.
- **비동기 처리로 성능 향상**: `asyncio`를 활용하여 크롤링을 비동기로 수행합니다.
- **데이터 추출**: 기사 페이지에서 `<h2>` 태그나 `<div>` 영역을 찾아 **제목**과 **본문** 텍스트를 추출합니다.

### 2. 기사 요약 및 감성 분석
- **KoBART 요약**: `digit82/kobart-summarization` 모델을 사용하여 기사 본문을 요약합니다.
- **감성 분석 (Sentiment)**: `snunlp/KR-FinBERT` 감성 분석 모델을 사용하여 긍정/부정/중립 분류를 수행합니다.
- **에러 처리**: 요약 또는 분석 중 오류가 발생할 경우 기본 메시지를 반환합니다.

### 3. 데이터 저장 및 조회 (`db.py`)
- **MySQL 연동**: `mysql-connector-python`을 사용하여 기사 데이터를 MySQL에 저장합니다.
- **기사 저장**: INSERT SQL 쿼리를 통해 데이터베이스에 저장하며, 중복 저장을 방지하고 예외 처리를 수행합니다.
- **기사 조회 및 삭제**: 특정 `article_id`를 기반으로 데이터를 조회 및 삭제하는 기능을 제공합니다.

### 4. FastAPI 기반 API 서버 (`server.py`)
- **REST API 엔드포인트 제공**: `/analyze_section/`, `/save_article/`, `/articles/`, `/article/{id}` 등의 API를 구현하여 백엔드 서비스를 제공합니다.
- **기사 저장 API**: FastAPI의 `BaseModel`을 활용하여 데이터 유효성을 검사한 후 MySQL에 저장합니다.
- **기사 조회 및 삭제 API**: 데이터베이스에 저장된 기사를 불러오거나 삭제할 수 있는 엔드포인트를 제공합니다.

### 5. Streamlit 기반 프론트엔드 (`app.py`)
- **대시보드 UI 구성**: Streamlit을 활용하여 사용자가 손쉽게 데이터를 조회할 수 있도록 UI를 구성했습니다.
- **뉴스 검색 페이지**: 사용자가 원하는 뉴스 섹션을 선택하여 검색을 실행할 수 있으며, FastAPI의 `/analyze_section/` API를 호출하여 결과를 받아옵니다.
- **검색 결과 및 상세보기**: 검색된 뉴스 목록에서 원하는 기사를 선택하면 상세 내용을 볼 수 있습니다.
- **저장된 기사 목록 및 관리**: 저장된 기사를 조회하고, 섹션별 필터링 및 삭제 기능을 제공합니다.

## 프로젝트의 가치 및 데이터 사이언스 활용
- **실시간 데이터 수집 및 처리**: 실시간으로 뉴스를 크롤링하여 최신 데이터를 확보하고 자동 분석을 수행합니다.
- **자연어 처리 모델 활용**: 요약 및 감성 분석 모델을 실무에 적용하여, 텍스트 데이터에서 유의미한 정보를 추출하는 NLP 기술을 활용했습니다.
- **웹 애플리케이션 통합 개발**: 크롤링, 데이터 저장, 모델 추론, API 서비스화, 프론트엔드 시각화까지 데이터 사이언스 프로젝트의 엔드투엔드 구현 경험을 제공합니다.
- **데이터 저장 및 활용**: MySQL을 활용하여 데이터를 구조적으로 저장하고 검색 및 관리할 수 있도록 했습니다.

## Flow Chart
- FastAPI, Streamlit, MySQL로 구성된 멀티 페이지 앱을 생성
- `app.py`:
  - streamlit을 통해 생성된 홈페이지로 구성 및 앱에 대한 설명(네이버 기사 크롤링 및 감정 분석)을 제공
- `server.py`:
  - FastAPI로 구성되어 있으며, CORS 설정을 통해 클라이언트와의 통신을 허용
  - 지정한 section에 대해 기사 크롤링, 저장, 조회, 삭제에 대한 API를 제공
  - 기사에 대한 요약 및 감성 분석을 실행하는 함수를 포함
- `db.py`:
  - MySQL 데이터베이스에 연결하고, section별 기사를 저장, 조회, 삭제하는 함수를 제공
- `schema.sql`:
  - 데이터베이스 TABLE을 생성하는 Query를 제공
- `pages/search.py`:
  - 기사의 크롤링을 요청한 개수만큼(default:5) 요청하고 요청 내용에 대한 오류, 혹은 완료 메시지를 반환
  - 여기서 크롤링할 기사의 개수는 직접 입력할 수 있도록 지정하여 검색 버튼 이벤트를 통해 서버에 전달
- `pages/result.py`:
  - `pages/search.py`에서 검색한 결과에 대해 기사 제목과, 내용의 첫 문장을 목록으로 출력
  - 해당 기사들의 항목을 체크박스를 이용해 선택할 수 있도록 지정하여 선택된 항목을 데이터베이스에 저장
  - 체크박스를 사용해서 선택된 기사를 상세 내용 버튼 이벤트를 통해 `pages/detail.py` 페이지에서 해당 기사의 id를 받아 상세 내용을 출력
- `pages/articles.py`:
  - 데이터베이스에 저장된 기사들을 로드하여 각 section 별로 출력하고, 각 기사 항목을 선택할 수 있도록 하여 선택 항목을 데이터베이스에서 삭제
  - 체크박스를 사용해서 선택된 기사를 상세 내용 버튼 이벤트를 통해 `pages/detail.py` 페이지에서 해당 기사의 id를 받아 상세 내용을 출력
- `pages/detail.py`:
  - 데이터베이스에 저장된 기사들 중 `pages/result.py`나 `pages/articles.py`에서 나타나는 기사들 중 선택된 항목에 대한 상세 내용을 출력
  - result, articles 페이지에서 링크를 통해 해당 페이지로 이동(해당 기능은 Streamlit의 session_state를 유지하는 기능 관련 이슈로 구현 실패)

---

### 요약 모델 파인튜닝 결과

```bash
📊 요약 성능 비교 결과 (ROUGE)

▶ ROUGE-1
  Pretrained: P=0.358, R=0.307, F1=0.321
  Fine-tuned: P=0.437, R=0.373, F1=0.391

▶ ROUGE-2
  Pretrained: P=0.220, R=0.183, F1=0.193
  Fine-tuned: P=0.297, R=0.246, F1=0.261

▶ ROUGE-L
  Pretrained: P=0.329, R=0.282, F1=0.295
  Fine-tuned: P=0.411, R=0.349, F1=0.367
```
- ROUGE는 자동 요약의 품질을 평가하기 위한 지표로, 주로 ROUGE-N과 ROUGE-L이 사용
- ROUGE-N: 생성된 요약과 참조 요약 간의 n-그램(연속된 n개의 단어) 중복을 측정
  - ROUGE-1: 단일 단어(유니그램) 중복을 평가
  - ROUGE-2: 2-그램(바이그램) 중복을 평가
- ROUGE-L: 생성된 요약과 참조 요약 간의 최장 공통 부분 수열(Longest Common Subsequence, LCS)을 기반으로 문장 구조의 유사성을 평가

#### 지표 해석
- 정밀도(Precision): 생성된 요약에서 참조 요약과 겹치는 부분의 비율을 나타내며, 요약의 정확성을 측정
- 재현율(Recall): 참조 요약에서 생성된 요약과 겹치는 부분의 비율을 나타내며, 원본 내용의 포괄성을 측정
- F1 점수: 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 평가
- 파인튜닝된 모델은 모든 지표에서 사전 학습된 모델보다 성능이 향상

ROUGE-1:
정밀도: 0.358 → 0.437 (향상: 0.079)​
재현율: 0.307 → 0.373 (향상: 0.066)​
F1 점수: 0.321 → 0.391 (향상: 0.070)​

ROUGE-2:
정밀도: 0.220 → 0.297 (향상: 0.077)​
재현율: 0.183 → 0.246 (향상: 0.063)​
F1 점수: 0.193 → 0.261 (향상: 0.068)​

ROUGE-L:
정밀도: 0.329 → 0.411 (향상: 0.082)​
재현율: 0.282 → 0.349 (향상: 0.067)​
F1 점수: 0.295 → 0.367 (향상: 0.072)